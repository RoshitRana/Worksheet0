{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdufdNsyo794wp8HsRf9TV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshitRana/Worksheet0/blob/main/Worsheet8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l3lNmZ6ZvlWY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d1f2a37b-9e9a-4fa3-8d80-5607bb687db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Decision Tree Accuracy: 0.8333\n",
            "Scikit-learn Decision Tree Accuracy: 1.0000\n",
            "Decision Tree F1 Score: 0.9440\n",
            "Random Forest F1 Score: 1.0000\n",
            "Best Random Forest Classifier Params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Decision Tree MSE: 0.1667\n",
            "Random Forest MSE: 0.0648\n",
            "Best Random Forest Regressor Params: {'n_estimators': 100, 'min_samples_split': 10, 'max_depth': None}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
        "\n",
        "# Load and split the Iris dataset for Decision Tree Comparison\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Implement Custom Decision Tree (from scratch) - Simplified\n",
        "class CustomDecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        unique_classes = np.unique(y)\n",
        "        if len(unique_classes) == 1:\n",
        "            return {\"class\": unique_classes[0]}\n",
        "        if self.max_depth and depth >= self.max_depth:\n",
        "            return {\"class\": np.bincount(y).argmax()}\n",
        "\n",
        "        best_feature = np.random.randint(X.shape[1])\n",
        "        best_threshold = np.median(X[:, best_feature])\n",
        "        left_mask = X[:, best_feature] <= best_threshold\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        return {\n",
        "            \"feature_idx\": best_feature,\n",
        "            \"threshold\": best_threshold,\n",
        "            \"left\": self._build_tree(X[left_mask], y[left_mask], depth + 1),\n",
        "            \"right\": self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
        "        }\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._predict_single(x, self.tree) for x in X]\n",
        "\n",
        "    def _predict_single(self, x, tree):\n",
        "        if \"class\" in tree:\n",
        "            return tree[\"class\"]\n",
        "        return self._predict_single(x, tree[\"left\"] if x[tree[\"feature_idx\"]] <= tree[\"threshold\"] else tree[\"right\"])\n",
        "\n",
        "# Train and Evaluate Custom Decision Tree\n",
        "custom_tree = CustomDecisionTree(max_depth=3)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "y_pred_custom = custom_tree.predict(X_test)\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
        "print(f\"Custom Decision Tree Accuracy: {accuracy_custom:.4f}\")\n",
        "\n",
        "# Train and Evaluate Scikit-learn Decision Tree\n",
        "sklearn_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "sklearn_tree.fit(X_train, y_train)\n",
        "y_pred_sklearn = sklearn_tree.predict(X_test)\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "print(f\"Scikit-learn Decision Tree Accuracy: {accuracy_sklearn:.4f}\")\n",
        "\n",
        "# Load and split Wine dataset for Ensemble Models\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and Compare Decision Tree and Random Forest Classifiers\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and F1-score comparison\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "print(f\"Decision Tree F1 Score: {f1_score(y_test, y_pred_dt, average='weighted'):.4f}\")\n",
        "print(f\"Random Forest F1 Score: {f1_score(y_test, y_pred_rf, average='weighted'):.4f}\")\n",
        "\n",
        "# Hyperparameter Tuning for Random Forest Classifier\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(f\"Best Random Forest Classifier Params: {grid_search.best_params_}\")\n",
        "\n",
        "# Train Decision Tree & Random Forest Regressors on Wine Data\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "dt_regressor.fit(X_train, y_train)\n",
        "rf_regressor = RandomForestRegressor(random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and Mean Squared Error comparison\n",
        "y_pred_dt_reg = dt_regressor.predict(X_test)\n",
        "y_pred_rf_reg = rf_regressor.predict(X_test)\n",
        "print(f\"Decision Tree MSE: {mean_squared_error(y_test, y_pred_dt_reg):.4f}\")\n",
        "print(f\"Random Forest MSE: {mean_squared_error(y_test, y_pred_rf_reg):.4f}\")\n",
        "\n",
        "# Hyperparameter Tuning for Random Forest Regressor\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "random_search = RandomizedSearchCV(RandomForestRegressor(random_state=42), param_dist, n_iter=5, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(f\"Best Random Forest Regressor Params: {random_search.best_params_}\")\n"
      ]
    }
  ]
}